{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hx8Q87pT_Wbh"
      },
      "source": [
        "# Custom Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "JXmwIhYq_Wbk"
      },
      "source": [
        "## In this tutorial, we provide an example of adapting usb to custom dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install semilearn==0.3.1\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "7fiicRcB_xi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mRPwzE2Q_Wbk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from semilearn import get_data_loader, get_net_builder, get_algorithm, get_config, Trainer\n",
        "from semilearn import split_ssl_data, BasicDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "KR-yboh1_Wbm"
      },
      "source": [
        "## Specifiy configs and define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OI0BAN1D_Wbn"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "config = {\n",
        "    'algorithm': 'flexmatch',\n",
        "    'net': 'vit_tiny_patch2_32',\n",
        "    'use_pretrain': True,\n",
        "    'pretrain_path': 'https://github.com/microsoft/Semi-supervised-learning/releases/download/v.0.0.0/vit_tiny_patch2_32_mlp_im_1k_32.pth',\n",
        "\n",
        "    # optimization configs\n",
        "    'epoch': 1,\n",
        "    'num_train_iter': 5000,\n",
        "    'num_eval_iter': 500,\n",
        "    'num_log_iter': 50,\n",
        "    'optim': 'AdamW',\n",
        "    'lr': 5e-4,\n",
        "    'layer_decay': 0.5,\n",
        "    'batch_size': 16,\n",
        "    'eval_batch_size': 16,\n",
        "\n",
        "\n",
        "    # dataset configs\n",
        "    'dataset': 'cifar10',\n",
        "    'num_labels': 450,\n",
        "    'num_classes': 2,\n",
        "    'img_size': 32,\n",
        "    'crop_ratio': 0.875,\n",
        "    'data_dir': './data',\n",
        "\n",
        "\n",
        "    # algorithm specific configs\n",
        "    'hard_label': True,\n",
        "    'uratio': 2,\n",
        "    'ulb_loss_ratio': 1.0,\n",
        "\n",
        "    # device configs\n",
        "    'gpu': 0,\n",
        "    'world_size': 1,\n",
        "    'distributed': False,\n",
        "    \"num_workers\": 2,\n",
        "}\n",
        "config = get_config(config)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "kqRYeWi3_Wbn"
      },
      "outputs": [],
      "source": [
        "# create model and specify algorithm\n",
        "algorithm = get_algorithm(config,  get_net_builder(config.net, from_name=False), tb_log=None, logger=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "rqwpM9yb_Wbo"
      },
      "source": [
        "## Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Read the JSON file into a dictionary\n",
        "with open(\"training_data.json\", \"r\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Convert this dictionary into a pandas DataFrame\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "kdXmM-1qDh-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list to np array of shape (10000, 32, 32, 3)\n",
        "df[\"image\"] = df[\"image\"].apply(lambda x: np.array(x).reshape((-1, 32, 32, 3)))\n",
        "\n",
        "# Get all of the values in the image column as a single np array of shape 10000,32,32,3\n",
        "images_array = np.squeeze(np.stack(df[\"image\"].values),axis=1)"
      ],
      "metadata": {
        "id": "K1Rx75uuHzos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set labels and check shape\n",
        "target = df[\"stables\"].values\n",
        "type(target)"
      ],
      "metadata": {
        "id": "8r_u0pjxK-KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and eval sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_images, eval_images, train_labels, eval_labels = train_test_split(images_array, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "7neV-1sLeUNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "TdTmJJtQ_Wbo"
      },
      "outputs": [],
      "source": [
        "# Add into a custom training dataset\n",
        "lb_data, lb_target, ulb_data, ulb_target = split_ssl_data(config, np.uint8(train_images), train_labels, 2,\n",
        "                                                          config.num_labels, include_lb_to_ulb=config.include_lb_to_ulb)\n",
        "\n",
        "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomCrop(32, padding=int(32 * 0.125), padding_mode='reflect'),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "train_strong_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "                                             transforms.RandomCrop(32, padding=int(32 * 0.125), padding_mode='reflect'),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "lb_dataset = BasicDataset(config.algorithm, lb_data, lb_target, config.num_classes, train_transform, is_ulb=False)\n",
        "ulb_dataset = BasicDataset(config.algorithm, lb_data, lb_target, config.num_classes, train_transform, is_ulb=True, strong_transform=train_strong_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2JOvCK2u_Wbo"
      },
      "outputs": [],
      "source": [
        "# Define eval dataset\n",
        "eval_transform = transforms.Compose([transforms.Resize(32),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "\n",
        "eval_dataset = BasicDataset(config.algorithm, np.uint8(eval_images), eval_labels, config.num_classes, eval_transform, is_ulb=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "7a1KLAGv_Wbp"
      },
      "outputs": [],
      "source": [
        "# define data loaders\n",
        "train_lb_loader = get_data_loader(config, lb_dataset, config.batch_size)\n",
        "train_ulb_loader = get_data_loader(config, ulb_dataset, int(config.batch_size * config.uratio))\n",
        "eval_loader = get_data_loader(config, eval_dataset, config.eval_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "q071w_eP_Wbp"
      },
      "source": [
        "## Training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "s1Z1Q6kV_Wbr"
      },
      "outputs": [],
      "source": [
        "# training and evaluation\n",
        "trainer = Trainer(config, algorithm)\n",
        "trainer.fit(train_lb_loader, train_ulb_loader, eval_loader)\n",
        "trainer.evaluate(eval_loader)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  trainer"
      ],
      "metadata": {
        "id": "eV61-u7lVCu7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "vscode": {
      "interpreter": {
        "hash": "efd87a861e5021e4a438e5b61d692cea261dd91508182bfdfdb13fb969975ffe"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}